---
raindrop_id: 1327037246
raindrop_highlights:
  68c43611606ead7ea7f4473a: c58cb53515228a38efe579e40fbec051
  68c43640639d3fd215dd89c6: 0d32439dc9b54d4c7a0377b98baf9b0f
  68c4365a49f0f533e439de93: f91d7d5fe62ad93ef3e2cd86efb47d3b
  68c4367b04fed0079c7b6fcb: 84b51f991dd3a14253ae73157f87b886
  68c436881959d9105a6c3abe: 5e616dbbad6e4aac8622839671e2bc35
  68c436bf68e3a85fa49b5bfd: 94187e222869a21aee6ff8ca8886eb8f
  68c436e368e3a85fa49b640d: 1002a85cb0297055e1d8f2f84bebe722
  68c436f122695b0c10a082b2: ff6b8da66952cfef7ca4730002ec516e
title: "Academics Build AI-Powered Android Vulnerability Discovery and Validation Tool - SecurityWeek"

description: |-
  Researchers have created a framework that relies on AI for the discovery and validation of vulnerabilities in Android applications.

source: https://www.securityweek.com/academics-build-ai-powered-android-vulnerability-discovery-and-validation-tool/

created: 1757187604491
type: article
tags:
  - "_index"

 
  - "AI" 
  - "LLM" 
  - "Android" 
  - "Tools"

---
# Academics Build AI-Powered Android Vulnerability Discovery and Validation Tool - SecurityWeek

![](https://www.securityweek.com/wp-content/uploads/2025/02/Android-update.jpeg)

> [!summary]
> Researchers have created a framework that relies on AI for the discovery and validation of vulnerabilities in Android applications.





Called A2, the framework mimics human analysis to identify vulnerabilities in Android applications and then validates them.
a framework that relies on AI for the discovery and validation of vulnerabilities in Android applications.
During the Agentic Vulnerability Discovery phase, semantic code understanding is mixed with traditional security tools to create vulnerability hypotheses. The next phase, the Agentic Vulnerability Validation, involves the planning, execution, and verification of exploitation operations to validate each hypothesis.
When fed an APK, A2 uses LLMs to analyze the code and generate speculative vulnerability findings. It also uses warnings from static application security testing (SAST) tools to generate additional findings, and consolidates all discoveries using an aggregator.
At the next phase, each finding is passed through a PoC planner that generates tasks and expected outcomes, each task is then executed, and a validator verifies the outcomes for iterative refinement
Next, the PoC planner analyzes each bug’s characteristics to plot a validation plan and eliminate false-positives, and assigns the tasks to the executor, which performs the validation steps across “code execution, device control, file system, static analysis, UI interaction, log analysis, APK generation, and web server management,” the researchers explain.

Finally, the validator independently verifies each PoC outcome, without accepting the task executor’s reported success. Instead, it relies on its own observations to verify that the expected results occurred.
The researchers tested the framework on a real-world dataset of 160 APKs. Of the 136 speculative vulnerabilities reported during the detection phase, 60 were validated as exploitable security defects, while 29 were marked as false positives.
Manual review showed that only three of the 60 validated bugs were false positives. The remaining 57 issues were cryptographic, access control, and input validation flaws that were responsibly disclosed.