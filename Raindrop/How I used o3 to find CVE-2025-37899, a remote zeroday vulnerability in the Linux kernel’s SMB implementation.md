---
raindrop_id: 1321645903
raindrop_highlights:
  68b68f7fe66eb5f7a4420338: c88ca9677e508e789cd2200c295613ad
  68b68f9853d8c0a7f5d04ed6: b0fa6f1790c602da973f9e19d8fe4fc2
  68b68fc9edf26eedb0141102: 5232b9b39267fe1bbae9f329276a7a60
  68b68fe7b8c384ecafd84815: 832a9289b19e32d02038c2a90c371802
  68b690984c98897a996a4338: 9bc12fce2cc655fca1fdbdc4a4d049f9
  68b690a3aade0e8529ef9ec9: 3e61fb05d2d39c3a3a5127f4b6218596
  68b690a8e66eb5f7a44234d5: 32cdee27237e648b4e1380f6e299f46b
  68b690d2411a215a113e6deb: 27470e414152d4938964570484151baa
  68b691032f64d3cdd2c9783a: d9abcf74f87049a4f685e7f5c3da34b5
  68b69154161546f2bf42ed87: a7d710b7a5775f578713edb487c88c81
  68b6916e65407e0ef524eaeb: e5223ac3a44604ec7d12a6b042413916
  68b6917ce66eb5f7a44259f9: 855990f7f3a8d28efd4c1929114b5bda
  68b69189aade0e8529efc80e: d15658ea6fdccafdc68df00e63aaaa91
  68b691b843de9ee60dc44cc5: 1b6936c65dac887de809c6f4fe9968dc
  68b691eb286e958bbbc10db7: fe74394d5d5dc6821050d95e5e6c00ec
  68b692074084d9664176a3c6: 07bdff8f1097540c07fb8fbe67899fc1
  68b692152f64d3cdd2c9a80d: 474ebc7507ffd50a164b541c43549bae
  68b6922c43de9ee60dc45f53: 56fa8680a5a41661956b907e9f5f8bfc
  68b6957fb9f724e29ca66fc9: 2f9f0c4a22cc174a0e002e0e3be6b655
  68b695c52eac52ecf7eaca62: ccf36127beefe0850be30cd5db6ddac7
  68b696daec380d7704528c7d: 1ea3c8062c8582e213b517b2dbb2f991
title: "How I used o3 to find CVE-2025-37899, a remote zeroday vulnerability in the Linux kernel’s SMB implementation"

description: |-
  In this post I’ll show you how I found a zeroday vulnerability in the Linux kernel using OpenAI’s o3 model. I found the vulnerability with nothing more complicated than the o3 API &#821…

source: https://sean.heelan.io/2025/05/22/how-i-used-o3-to-find-cve-2025-37899-a-remote-zeroday-vulnerability-in-the-linux-kernels-smb-implementation

created: 1747909530000
type: article
tags:
  - "_index"

 
  - "AI" 
  - "LLM" 
  - "vuln-research-blog"

---
# How I used o3 to find CVE-2025-37899, a remote zeroday vulnerability in the Linux kernel’s SMB implementation

![](https://sean.heelan.io/wp-content/uploads/2009/05/cropped-oxford_7602.jpg?w=200)

> [!summary]
> In this post I’ll show you how I found a zeroday vulnerability in the Linux kernel using OpenAI’s o3 model. I found the vulnerability with nothing more complicated than the o3 API &#821…





I’ll show you how I found a zeroday vulnerability in the Linux kernel using OpenAI’s o3 model.
I found the vulnerability with nothing more complicated than the o3 API – no scaffolding, no agentic frameworks, no tool use.
The vulnerability it found is CVE-2025-37899 (fix here), a use-after-free in the handler for the SMB ‘logoff’ command.
Understanding the vulnerability requires reasoning about concurrent connections to the server, and how they may share various objects in specific circumstances. o3 was able to comprehend this and spot a location where a particular object that is not referenced counted is freed while still being accessible by another thread
OK, so we have the vulnerability we want to use for evaluation, now what code do we show the LLM to see if it can find it?
The ideal use of an LLM is we give it all the code from a repository, it ingests it and spits out results.
However, due to context window limitations and regressions in performance that occur as the amount of context increases, this isn’t practically possible right now.
Instead, I thought one possible way that an automated tool could generate context for the LLM was through expansion of each SMB command handler individually. So, I gave the LLM the code for the ‘session setup’ command handler, including the code for all functions it calls, and so on, up to a call depth of 3 (this being the depth required to include all of the code necessary to reason about the vulnerability).
I also include all of the code for the functions that read data off the wire, parses an incoming request, selects the command handler to run, and then tears down the connection after the handler has completed. Without this the LLM would have to guess at how various data structures were set up and that would lead to more false positives
If you’re interested, the code to be analysed is here as a single file, created with the files-to-prompt tool.
You can find the system prompt and the other information I provided to the LLM in the .prompt files in this Github repository.
To run the query I then use the llm tool (github) like:
$ llm --sf system_prompt_uafs.prompt                \ 
        -f session_setup_code.prompt                \          
        -f ksmbd_explainer.prompt                   \
        -f session_setup_context_explainer.prompt   \
        -f audit_request.prompt
o3 finds the kerberos authentication vulnerability in the benchmark in 8 of the 100 runs.
o3 finds a 0-day (CVE-2025-37899)
Having confirmed that o3 can find the kerberos authentication vulnerability (CVE-2025-37778) when given the code for the session setup command handler, I wanted to see if it could find it if I give it the code for all of the command handlers.
Combining the code for all of the handlers with the connection setup and teardown code, as well as the command handler dispatch routines, ends up at about 12k LoC (~100k input tokens), and as before I ran the experiment 100 times.
o3 finds the kerberos authentication vulnerability in 1 out of 100 runs with this larger number of input tokens, so a clear drop in performance, but it does still find it. More interestingly however, in the output from the other runs I found a report for a similar, but novel, vulnerability that I did not previously know about.
I felt my expectations shift on how helpful AI tools are going to be in vulnerability research.
Conclusion
LLMs exist at a point in the capability space of program analysis techniques that is far closer to humans than anything else we have seen. Considering the attributes of creativity, flexibility, and generality, LLMs are far more similar to a human code auditor than they are to symbolic execution, abstract interpretation or fuzzing.